# Image Segmentation Keras

[Image Segmentation Keras : Implementation of Segnet, FCN, UNet, PSPNet and other models in Keras.](https://divamgupta.com/image-segmentation/2019/06/06/deep-learning-semantic-segmentation-keras.html), 
using Tensorflow 1.14.0.

Making use of the [image-segmentation-keras](https://github.com/divamgupta/image-segmentation-keras) project.

## Version

image-segmentation-keras version: 0.3.0

## Docker

### Quick start

* Log into registry using *public* credentials:

  ```commandline
  docker login -u public -p public public.aml-repo.cms.waikato.ac.nz:443 
  ```

* Pull and run image (adjust volume mappings `-v`):

  ```commandline
  docker run --gpus=all \
    -v /local/dir:/container/dir \
    -it public.aml-repo.cms.waikato.ac.nz:443/tensorflow/image-segmentation-keras:1.14.0_0.3.0
  ```

  **NB:** For docker versions older than 19.03 (`docker version`), use `--runtime=nvidia` instead of `--gpus=all`.

* If need be, remove all containers and images from your system:

  ```commandline
  docker stop $(docker ps -a -q) && docker rm $(docker ps -a -q) && docker system prune -a
  ```


### Build local image

* Build image `isk` from Docker file (from within /path_to/tensorflow/image-segmentation-keras/1.14.0_0.3.0)

  ```commandline
  docker build -t isk .
  ```
  
* Run image `isk` in interactive mode (i.e., using `bash`) as container `isk_container`

  ```commandline
  docker run --gpus=all --name isk_container -ti -v \
    /local/dir:/container/dir \
    isk bash
  ```

### Pre-built images

* Build

  ```commandline
  docker build -t tensorflow/isk:1.14.0_0.3.0 .
  ```
  
* Tag

  ```commandline
  docker tag \
    tensorflow/isk:1.14.0_0.3.0 \
    public-push.aml-repo.cms.waikato.ac.nz:443/tensorflow/image-segmentation-keras:1.14.0_0.3.0
  ```
  
* Push

  ```commandline
  docker push public-push.aml-repo.cms.waikato.ac.nz:443/tensorflow/image-segmentation-keras:1.14.0_0.3.0
  ```
  If error "no basic auth credentials" occurs, then run (enter username/password when prompted):
  
  ```commandline
  docker login public-push.aml-repo.cms.waikato.ac.nz:443
  ```
  
* Pull

  If image is available in aml-repo and you just want to use it, you can pull using following command and then [run](#run).

  ```commandline
  docker pull public.aml-repo.cms.waikato.ac.nz:443/tensorflow/image-segmentation-keras:1.14.0_0.3.0
  ```
  If error "no basic auth credentials" occurs, then run (enter username/password when prompted):
  
  ```commandline
  docker login public.aml-repo.cms.waikato.ac.nz:443
  ```
  Then tag by running:
  
  ```commandline
  docker tag \
    public.aml-repo.cms.waikato.ac.nz:443/tensorflow/image-segmentation-keras:1.14.0_0.3.0 \
    tensorflow/isk:1.14.0_0.3.0
  ```
  
* <a name="run">Run</a>

  ```commandline
  docker run --gpus=all -v /local/dir:/container/dir -it tensorflow/isk:1.14.0_0.3.0
  ```
  `/local/dir:/container/dir` maps a local disk directory into a directory inside the container

### Caching of models

Keras will cache the base models it uses. However, when using Docker, these cached images will
disappear once the container is exited/stopped. To avoid constant downloads, you can
map the cache directory used in the container to a directory on the host. 

* Map cache directory (`/root/.keras`) when running container as root:

  ```commandline  
  -v /local/dir/keras_cache:/root/.keras
  ```

* Or when running as regular user (`/tmp/.keras`):

  ```commandline  
  -v /local/dir/keras_cache:/tmp/.keras
  ```


## Tools

* `keras_seg` - shortcut for `python -m keras_segmentation`
* `keras_seg_conv` - converts indexed PNGs into PNG files with the indices in the blue channel 
* `keras_seg_poll` - for continuous predictions, monitors input directory for new images to process 
* `keras_seg_redis` - for continuous predictions via redis 
* `keras_seg_train` - like `keras_seg train` but with more options exposed 


## Usage

* [Training](https://github.com/divamgupta/image-segmentation-keras#training-the-model)
* [Predicting](https://github.com/divamgupta/image-segmentation-keras#getting-the-predictions)
* [Predicting (video)](https://github.com/divamgupta/image-segmentation-keras#video-inference)
* [Evaluation](https://github.com/divamgupta/image-segmentation-keras#model-evaluation)

**Notes:**

* In case of training, the `--input_height` and `--input_width` parameters must be multiples of 32.


## Permissions

When running the docker container as regular use, you will want to set the correct
user and group on the files generated by the container (aka the user:group launching
the container):

```commandline
docker run -u $(id -u):$(id -g) ...
```

## Examples

### Start docker container

The following command starts up the docker container, which is used for the examples further down:
* the datasets are stored in `/some/where/keras/data`, mapped to `/data`
* the models etc are getting stored in `/some/where/keras/output`, mapped to `/output`
* the predictions (in/out directories) are located in `/some/where/keras/predictions`, mapped to `/predictions`  

```commandline
docker run --gpus=all -u $(id -u):$(id -g) \
  -v /some/where/keras/data:/data \
  -v /some/where/keras/output:/output \
  -v /some/where/keras/cache:/tmp/.keras \
  -v /some/where/keras/predictions:/predictions \
  -it public.aml-repo.cms.waikato.ac.nz:443/tensorflow/image-segmentation-keras:1.14.0_0.3.0
```

### Convert

Converts the PNGs with indexed palette in `/data/cooldataset/indexed/` into regular RBG ones and
stores them in `/data/cooldataset/annotations/`: 

```commandline
keras_seg_conv \
  --input_dir /data/cooldataset/indexed/ \
  --output_dir /data/cooldataset/annotations/ \
  --verbose
```

### Train

Trains `resnet50_unet` for 5 epochs on our *cooldataset*, using the original images in `/data/cooldataset/images/`
and the converted RGB images in `/data/cooldataset/annotations/`. The number of classes is two, background and the
single type of object that we are interested in. The images get scaled to 1024x704 (multiples of 32).

```commandline
keras_seg train \
  --checkpoints_path=/output/cooldataset/ \
  --train_images=/data/cooldataset/images/ \
  --train_annotations=/data/cooldataset/annotations/ \
  --epochs=5 \
  --n_classes=2 \
  --input_height=704 \
  --input_width=1024 \
  --model_name=resnet50_unet
```

### Predict

Once trained, we can use our model to continuously process images and generate predictions. New images get picked up
from `/predictions/in` and the generated prediction images (and original input images) get output in `/predictions/out`:

```commandline
keras_seg_poll \
  --checkpoints_path /output/cooldataset/ \
  --prediction_in /predictions/in \
  --prediction_out /predictions/out \
  --continuous
```

You can provide a custom color palette as well, using the `--colors` parameter. The following example uses
black, red and blue, with the remainder of the 256 PNG palette getting filled up with random colors:

```commandline
keras_seg_poll \
  --checkpoints_path /output/cooldataset/ \
  --prediction_in /predictions/in \
  --prediction_out /predictions/out \
  --colors 0,0,0,255,0,0,0,0,255 \
  --continuous
```

Use `--use_watchdog` to react to file creation events rather than using fixed-interval polling.

Using `--remove_background` (and no colors), you can output the original image with only the 
identified segments left over (the image segmentation regions are used as a mask).  